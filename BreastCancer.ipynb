{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthayeep/ADS_assignment/blob/main/BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNO9hbmE2qis"
      },
      "source": [
        "#Data Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eky3RUKcq57D"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B5DGdPXlW5R"
      },
      "source": [
        "###Dataset\n",
        "https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QkcBjeLye68"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u7UtJsdgFa5"
      },
      "outputs": [],
      "source": [
        "# a folder to store images\n",
        "import os\n",
        "output_dir = 'histograms'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6dFg6JUy-oU"
      },
      "outputs": [],
      "source": [
        "# Import datasets\n",
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwB2qOrwzQq4"
      },
      "outputs": [],
      "source": [
        "# View the first five rows of the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8GqNemT14j2"
      },
      "outputs": [],
      "source": [
        "# Information on the datasets\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94R81eQY1_E2"
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics on the datasets\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8a1e1-Q2NAq"
      },
      "outputs": [],
      "source": [
        "# Give the name of all the columns in the datasets\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8sVd_TE2R5J"
      },
      "outputs": [],
      "source": [
        "# Give the number of rows and columns in the datasets\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dfUvMEz21mn"
      },
      "source": [
        "#Data Visualisation\n",
        "Use visual methods to find the key features, patterns, and trends in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKEx_6ff24If"
      },
      "outputs": [],
      "source": [
        "# Separate the labels (y) and the features (x)\n",
        "# Drop unnamed features and id\n",
        "y = df.diagnosis\n",
        "x = df.drop(['Unnamed: 32', 'id', 'diagnosis'], axis=1)\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlPlWScXWOPH"
      },
      "outputs": [],
      "source": [
        "# Compare the value of benign and malignant tumour\n",
        "ax = sns.countplot(y,label=\"Count\")\n",
        "B, M = y.value_counts()\n",
        "print('Number of Benign: ',B)\n",
        "print('Number of Malignant : ',M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-yBYeFhTfPL"
      },
      "outputs": [],
      "source": [
        "#Set the background to white and use color codes\n",
        "sns.set(style=\"white\", color_codes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RlS_8W-Z0Fo"
      },
      "outputs": [],
      "source": [
        "# Show the heatmap\n",
        "f,ax = plt.subplots(figsize=(18, 18))\n",
        "sns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRJkNxoVbuyk"
      },
      "outputs": [],
      "source": [
        "# Drop the correlated features\n",
        "drop_list1 = ['perimeter_mean','radius_mean','compactness_mean','concave points_mean','radius_se','perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst','compactness_se','concave points_se','texture_worst','area_worst']\n",
        "x_1 = x.drop(drop_list1,axis = 1 )        # do not modify x, we will use it later\n",
        "x_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vubhZYsbb0Y_"
      },
      "outputs": [],
      "source": [
        "# Show the heatmap after dropping correlated features\n",
        "f,ax = plt.subplots(figsize=(14, 14))\n",
        "sns.heatmap(x_1.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b9iv-X5BeRfU"
      },
      "outputs": [],
      "source": [
        "# Encode the label\n",
        "y = df['diagnosis'].replace({'M': 1, 'B': 0})\n",
        "\n",
        "# Create a new DataFrame combining x_1 and y\n",
        "df_combined = x_1.copy()\n",
        "df_combined['diagnosis'] = y\n",
        "\n",
        "# Plot histograms for each feature in x_1, separated by diagnosis\n",
        "features = x_1.columns\n",
        "\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=df_combined, x=feature, hue='diagnosis', element='step', stat='density', common_norm=False)\n",
        "    plt.title(f'Histogram of {feature} by Diagnosis')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend(title='Diagnosis', labels=['Benign', 'Malignant'])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkQTOc7oWh7x"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_dia = y\n",
        "data = x_1\n",
        "\n",
        "# Perform standardization\n",
        "data_n_2 = (data - data.mean()) / (data.std())\n",
        "\n",
        "# Iterate through all features and create a separate violin plot for each\n",
        "for feature in data.columns:\n",
        "    # Prepare data for plotting\n",
        "    plot_data = pd.concat([y, data_n_2[[feature]]], axis=1)\n",
        "    plot_data = pd.melt(plot_data, id_vars=\"diagnosis\", var_name=\"features\", value_name='value')\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=plot_data, split=True, inner=\"quart\")\n",
        "    plt.title(f'Violin Plot of {feature} by Diagnosis')\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Value')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "90nbW2fhJvSF"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features = x_1.columns\n",
        "\n",
        "# Create separate boxplots for each feature\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
        "    sns.boxplot(x=df['diagnosis'], y=df[feature])\n",
        "    plt.title(f'Boxplot of {feature} by Diagnosis')\n",
        "    plt.xlabel('Diagnosis')\n",
        "    plt.ylabel(feature)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnbY6srfzi2f"
      },
      "source": [
        "#Data Preprocessing\n",
        "Demonstrate understanding of data preprocessing techniques by performing any of the following, as needed, according to the chosen dataset: (minimum 2)\n",
        "1.\tPerform data cleaning, transformation, discretization, and normalization.\n",
        "2.\tSelect and justify data sampling techniques.\n",
        "3.\tRemove any irrelevant data or outliers.\n",
        "4.\tFeature selection and feature engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY5SzsaRR_-M"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUvHwAijqkvW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Drop unnecessary columns\n",
        "drop_list1 = ['id', 'perimeter_mean', 'radius_mean', 'compactness_mean', 'concave points_mean', 'radius_se',\n",
        "              'perimeter_se', 'radius_worst', 'perimeter_worst', 'compactness_worst', 'concave points_worst',\n",
        "              'compactness_se', 'concave points_se', 'texture_worst', 'area_worst']\n",
        "x_1 = df.drop(drop_list1, axis=1)\n",
        "\n",
        "# Encode the target variable\n",
        "y = df['diagnosis'].replace({'M': 1, 'B': 0})\n",
        "\n",
        "# Create a new DataFrame combining x_1 and y\n",
        "df_combined = x_1.copy()\n",
        "df_combined['diagnosis'] = y\n",
        "\n",
        "# Data cleaning\n",
        "# Missing values before dropping columns\n",
        "missing_values_before = df_combined.isnull().sum()\n",
        "print(\"*Missing values in each column (Before Dropping Columns):\\n\", missing_values_before)\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicate = df_combined.duplicated().sum()\n",
        "print(\"*Number of duplicate rows:\", duplicate)\n",
        "\n",
        "# Drop columns with all missing values\n",
        "X = df_combined.dropna(axis=1, how='all')\n",
        "\n",
        "# Print column names with all missing values\n",
        "print(\"Columns with all missing values (After Dropping Columns):\")\n",
        "print(X.columns[X.isnull().all()])\n",
        "\n",
        "# Missing values after dropping columns\n",
        "missing_values_after = X.isnull().sum()\n",
        "print(\"*Missing values in each column (After Dropping Columns):\\n\", missing_values_after)\n",
        "\n",
        "# Define features and target\n",
        "X = X.drop('diagnosis', axis=1)\n",
        "y = df_combined['diagnosis']\n",
        "\n",
        "# Split the data into training and test sets using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uJYlMxbAuCJ"
      },
      "source": [
        "3. Handling Outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU83Vwp8AsTn"
      },
      "outputs": [],
      "source": [
        "# Handle outliers and impute missing values\n",
        "def handle_outliers_and_impute(df):\n",
        "    df_cleaned = df.copy()\n",
        "\n",
        "    # Dictionaries to store outlier information\n",
        "    outliers_before = {}\n",
        "    outliers_after = {}\n",
        "\n",
        "    for col in df_cleaned.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df_cleaned[col]):\n",
        "            Q1 = df_cleaned[col].quantile(0.25)\n",
        "            Q3 = df_cleaned[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "            # Identify outliers\n",
        "            outliers_before[col] = (df_cleaned[col] < lower_bound) | (df_cleaned[col] > upper_bound)\n",
        "            num_outliers_before = outliers_before[col].sum()\n",
        "\n",
        "            # Impute outliers with median\n",
        "            median = df_cleaned[col].median()\n",
        "            df_cleaned.loc[outliers_before[col], col] = median\n",
        "\n",
        "            # Verify the number of outliers after imputation\n",
        "            outliers_after[col] = (df_cleaned[col] < lower_bound) | (df_cleaned[col] > upper_bound)\n",
        "            num_outliers_after = outliers_after[col].sum()\n",
        "\n",
        "    # Print total outliers before and after imputation\n",
        "    print(\"\\nTotal number of outliers per column before imputation:\")\n",
        "    for col, outliers in outliers_before.items():\n",
        "        print(f\"{col}: {outliers.sum()}\")\n",
        "\n",
        "    print(\"\\nTotal number of outliers per column after imputation:\")\n",
        "    for col, outliers in outliers_after.items():\n",
        "        print(f\"{col}: {outliers.sum()}\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# Handle outliers and impute missing values in training data\n",
        "X_train_cleaned = handle_outliers_and_impute(X_train)\n",
        "y_train_cleaned = y_train.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fqJwaX2Aa78"
      },
      "source": [
        "SMOTE (Data Sampling techniquen to remove bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fyCIlE2AVFV"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Define SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply SMOTE\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_cleaned, y_train)\n",
        "\n",
        "# Convert to DataFrames for easier visualization\n",
        "df_before = pd.DataFrame({'class': y_train})\n",
        "df_after = pd.DataFrame({'class': y_train_res})\n",
        "\n",
        "# Plot the class distribution before SMOTE\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(x='class', data=df_before)\n",
        "plt.title('Class Distribution Before SMOTE')\n",
        "\n",
        "# Plot the class distribution after SMOTE\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x='class', data=df_after)\n",
        "plt.title('Class Distribution After SMOTE')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display class counts before and after SMOTE\n",
        "print(\"Class distribution before SMOTE:\")\n",
        "print(df_before['class'].value_counts())\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(df_after['class'].value_counts())\n",
        "\n",
        "# Display a sample of the resampled data\n",
        "sample_size = 5\n",
        "print(\"\\nSample of resampled X_train_res:\")\n",
        "print(pd.DataFrame(X_train_res).head(sample_size))\n",
        "\n",
        "print(\"\\nSample of resampled y_train_res:\")\n",
        "print(pd.Series(y_train_res).head(sample_size))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Meo0pSMb_L6z"
      },
      "source": [
        "4. Feature Selection and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g_sIDrN_IN0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "def feature_engineering(df):\n",
        "\n",
        "    numeric_features = df.select_dtypes(include=['number']).columns\n",
        "    categorical_features = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Polynomial features\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    poly_features = poly.fit_transform(df[numeric_features])\n",
        "    poly_feature_names = poly.get_feature_names_out(numeric_features)\n",
        "\n",
        "    # Create DataFrame with polynomial features\n",
        "    df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
        "\n",
        "    # Combine with original features\n",
        "    df_combined = pd.concat([df.reset_index(drop=True), df_poly.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Drop duplicates if any\n",
        "    df_combined = df_combined.loc[:, ~df_combined.columns.duplicated()]\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "# Apply feature engineering\n",
        "X_train_fe = feature_engineering(X_train_res)\n",
        "X_test_fe = feature_engineering(X_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGLDVauoBc_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Feature Selection\n",
        "def feature_selection(X_train_fe, y_train):\n",
        "\n",
        "    numeric_features = X_train_fe.select_dtypes(include=['number']).columns\n",
        "    categorical_features = X_train_fe.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Define preprocessing steps for feature selection\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
        "            ('cat', OneHotEncoder(), categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Apply preprocessing\n",
        "    X_train_preprocessed = preprocess.fit_transform(X_train_fe)\n",
        "\n",
        "    # RFE with RandomForest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "    X_train_rfe = rfe.fit_transform(X_train_preprocessed, y_train)\n",
        "    rfe_df = pd.DataFrame({'Feature': preprocess.get_feature_names_out(), 'RFE Ranking': rfe.ranking_}).sort_values(by='RFE Ranking')\n",
        "\n",
        "    return rfe_df\n",
        "\n",
        "# Apply feature selection to feature-engineered data\n",
        "rfe_df = feature_selection(X_train_res, y_train_res)\n",
        "\n",
        "print(\"\\nRFE Ranking:\")\n",
        "print(rfe_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkNPjvDuprFe"
      },
      "outputs": [],
      "source": [
        "# Select top features based on RFE ranking\n",
        "top_features = rfe_df[rfe_df['RFE Ranking'] == 1]['Feature']\n",
        "\n",
        "# Extract the original feature names by removing the 'num__' or 'cat__' prefix\n",
        "original_feature_names = [name.split('__')[1] for name in top_features]\n",
        "\n",
        "# Select the top features from the resampled X_train_res and X_test_fe\n",
        "X_train_selected = X_train_res[original_feature_names]\n",
        "X_test_selected = X_test_fe[original_feature_names]\n",
        "\n",
        "# Display the top selected features\n",
        "print(\"\\nTop selected features based on RFE ranking:\")\n",
        "print(original_feature_names)\n",
        "\n",
        "print(\"Shape of X_train_selected:\", X_train_selected.shape)\n",
        "print(\"Shape of y_train_res:\", y_train_res.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Xcn0syzk5x"
      },
      "source": [
        "#Data Mining Methods\n",
        "*\tDevelop data mining models to achieve the objective in Task 1. (Minimum 3 models)  \n",
        "*\tEvaluate the data mining models to ensure that the model is accurate and reliable.  \n",
        "*\tPerform hyperparameter tuning or revisit the preprocessing task to improve the modelsâ€™ performances.  \n",
        "*\tDiscuss the results.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKLnmXta9pF"
      },
      "source": [
        "##KNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYaqkUyQS8Dz"
      },
      "source": [
        "Training with Dataset only after remove missing value\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Range of k values\n",
        "k_range = range(1, 10)\n",
        "train_accuracy1 = []\n",
        "test_accuracy1 = []\n",
        "\n",
        "# Loop through k values\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    cv_scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    train_accuracy1.append(np.mean(cv_scores))\n",
        "    test_accuracy1.append(np.mean(cv_scores))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(k_range, train_accuracy1, label='Train Accuracy')\n",
        "plt.plot(k_range, test_accuracy1, label='Test Accuracy')\n",
        "plt.xlabel('Number of Neighbors K')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "evIhqMHITmwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qgawrgDYW76"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "# Train the KNN model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f'KNN Accuracy (After Dropping Duplicates and Handling Missing Values): {accuracy_knn:.2f}')\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nKNN Classification Report (After Dropping Duplicates and Handling Missing Values):\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "# Output confusion matrix values\n",
        "print(\"\\nKNN Confusion Matrix (After Dropping Duplicates and Handling Missing Values):\")\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu',\n",
        "            xticklabels=['Class 0', 'Class 1'],\n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ulEKcyiVpWe"
      },
      "source": [
        "KNN model after dropping unnecessary value and outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeGYfFvJS7te"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(X_train_cleaned, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f'KNN Accuracy (After Removing Outliers and Handling Missing Values): {accuracy_knn:.2f}')\n",
        "print(\"\\nKNN Classification Report (After Removing Outliers and Handling Missing Values):\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "print(\"\\nKNN Confusion Matrix (After Removing Outliers and Handling Missing Values):\")\n",
        "print(cm_knn)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm_knn, annot=True, fmt='g', cmap='YlGnBu',\n",
        "            xticklabels=['Class 0', 'Class 1'],\n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix Heatmap (After Removing Outliers and Handling Missing Values)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSt8xrmsWLfc"
      },
      "source": [
        "KNN model after dropping unnessary value and outlier and applying SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1HeHq2cS7rf"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(X_train_res, y_train_res)\n",
        "y_pred_knn_smote = knn.predict(X_test)\n",
        "accuracy_knn_smote = accuracy_score(y_test, y_pred_knn_smote)\n",
        "print(f'KNN Accuracy (After SMOTE): {accuracy_knn_smote:.2f}')\n",
        "print(\"\\nKNN Classification Report (After SMOTE):\")\n",
        "print(classification_report(y_test, y_pred_knn_smote))\n",
        "cm_knn_smote = confusion_matrix(y_test, y_pred_knn_smote)\n",
        "print(\"\\nKNN Confusion Matrix (After SMOTE):\")\n",
        "print(cm_knn_smote)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm_knn_smote, annot=True, fmt='g', cmap='YlGnBu',\n",
        "            xticklabels=['Class 0', 'Class 1'],\n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix Heatmap (After SMOTE)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmlq9rAuS0cT"
      },
      "source": [
        "after all preprocessing step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLpbgCDva76r"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(X_train_selected, y_train_res)\n",
        "y_pred_knn_selected = knn.predict(X_test_selected)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn_selected)\n",
        "print(f'KNN Accuracy (After Feature Selection): {accuracy_knn:.2f}')\n",
        "print(\"\\nKNN Classification Report (After Feature Selection):\")\n",
        "print(classification_report(y_test, y_pred_knn_selected))\n",
        "cm_knn_selected = confusion_matrix(y_test, y_pred_knn_selected)\n",
        "print(\"\\nKNN Confusion Matrix (After Feature Selection):\")\n",
        "print(cm_knn_selected)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm_knn_selected, annot=True, fmt='g', cmap='YlGnBu',\n",
        "            xticklabels=['Class 0', 'Class 1'],\n",
        "            yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix Heatmap (After Feature Selection)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w08L7FhdbFQO"
      },
      "source": [
        "##NAIVE BAYES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enkBcAxBdcYI"
      },
      "source": [
        "Training with Dataset only after remove missing value\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu',\n",
        "                xticklabels=['Class 0', 'Class 1'],\n",
        "                yticklabels=['Class 0', 'Class 1'])\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vpz7q1IBjwhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptDflPZCfP-T"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f'Naive Bayes Accuracy: {accuracy_nb:.2f}')\n",
        "print(\"\\nNaive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"\\nNaive Bayes Confusion Matrix:\")\n",
        "print(cm_nb)\n",
        "plot_confusion_matrix(cm_nb, 'Confusion Matrix Heatmap (After removing missing and duplicate data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Vfl2Midr9b"
      },
      "source": [
        "\n",
        "model after dropping unnessary value and outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN77booDfQPw"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train_cleaned, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f'Naive Bayes Accuracy (After Outlier Handling and Imputation): {accuracy_nb:.2f}')\n",
        "print(\"\\nNaive Bayes Classification Report (After Outlier Handling and Imputation):\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"\\nNaive Bayes Confusion Matrix (After Outlier Handling and Imputation):\")\n",
        "print(cm_nb)\n",
        "plot_confusion_matrix(cm_nb, 'Confusion Matrix Heatmap (After Outlier Handling and Imputation)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQHr2XIAdslZ"
      },
      "source": [
        "KNN model after dropping unnessary value and outlier and applying SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BBye70cdZPK"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train_res, y_train_res)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f'Naive Bayes Accuracy (After SMOTE): {accuracy_nb:.2f}')\n",
        "print(\"\\nNaive Bayes Classification Report (After SMOTE):\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"\\nNaive Bayes Confusion Matrix (After SMOTE):\")\n",
        "print(cm_nb)\n",
        "plot_confusion_matrix(cm_nb, 'Confusion Matrix Heatmap (After SMOTE)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_4n_hnMdGSv"
      },
      "source": [
        "after all preprocessing step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EYT9tYKa7up"
      },
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train_selected, y_train_res)\n",
        "y_pred_nb = nb.predict(X_test_selected)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f'Naive Bayes Accuracy: {accuracy_nb:.2f}')\n",
        "print(\"\\nNaive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"\\nNaive Bayes Confusion Matrix:\")\n",
        "print(cm_nb)\n",
        "plot_confusion_matrix(cm_nb, 'Confusion Matrix Heatmap (After Feature Selection)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbZNWPZgXwaY"
      },
      "source": [
        "##Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phhQM5nJYR2q"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUDDOVlAjIPr"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# param_grid = {\n",
        "#     'max_depth': [None, 10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'criterion': ['gini', 'entropy']\n",
        "# }\n",
        "# grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
        "# grid_search.fit(X_train_selected, y_train_res)\n",
        "# best_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYa455h2jkn1"
      },
      "outputs": [],
      "source": [
        "# best_params = grid_search.best_params_\n",
        "# print(f\"Best Parameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZnyqM0RbX_0"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the Decision tree classifier\n",
        "dt_clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "\n",
        "# Train the model on the training data after feature selection\n",
        "dt_clf.fit(X_train_selected, y_train_res)\n",
        "\n",
        "# Make a prediction\n",
        "y_pred = dt_clf.predict(X_test_selected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsDmqgDscBKw"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Feature Selection)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja9D47O8ojUO"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the Decision tree classifier\n",
        "dt_clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "\n",
        "# Train the model on the training data before feature selection\n",
        "dt_clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Make a prediction\n",
        "y_pred = dt_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh2aIvewphgv"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Feature Selection)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A33dC674pvA2"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the Decision tree classifier\n",
        "dt_clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "\n",
        "# Train the model on the training data before handling outliers\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction\n",
        "y_pred = dt_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua05poGLqFLD"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Handling Outliers)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yGxvrEyYSmb"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhitzuoFhEJ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4yrfWMokiev"
      },
      "outputs": [],
      "source": [
        "# Perform a grid search to find the best parameters\n",
        "param_grid = {\n",
        "    'max_depth': [10, 20, None],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'n_estimators': [100, 200]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smn0XqwNkt7Z"
      },
      "outputs": [],
      "source": [
        "# #Create a Random forest classifier\n",
        "# model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# # Initialize the a GridSearchCV object\n",
        "# grid_search = GridSearchCV(\n",
        "#     estimator=model,\n",
        "#     param_grid=param_grid,\n",
        "#     cv=5,                            # Number of folds in cross-validation\n",
        "#     scoring='accuracy',              # Metric to evaluate\n",
        "#     n_jobs=-1,                       # Use all available cores\n",
        "#     verbose=1                        # Print progress\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXrIvItklJRh"
      },
      "outputs": [],
      "source": [
        "# # Run the grid search on the training data\n",
        "# grid_search.fit(X_train_selected, y_train_res)\n",
        "\n",
        "# # Get the best parameters from the grid search\n",
        "# best_params = grid_search.best_params_\n",
        "# print(f\"Best Parameters: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-ACybRFhIZc"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the random forest classifier with 100 number of trees\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    max_features='sqrt',\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the data after feature selection into the model\n",
        "rf_clf.fit(X_train_selected, y_train_res)\n",
        "\n",
        "# Make a prediction using the model\n",
        "y_pred = rf_clf.predict(X_test_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4CKOA_IhfWT"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Feature Selection)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCTmoMA1hojI"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the random forest classifier with 100 number of trees\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    max_features='sqrt',\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the data before feature selection into the model\n",
        "rf_clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Make a prediction using the model\n",
        "y_pred = rf_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqxw1Ri5qWeW"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Feature Selection)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipaVk0eMqlES"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the random forest classifier with 100 number of trees\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    max_features='sqrt',\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the data before handling outliers into the model\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction using the model\n",
        "y_pred = rf_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrvqRyqKqspY"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Handling Outliers)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiqjnTNUr0YA"
      },
      "source": [
        "## Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after all preprocessing\n"
      ],
      "metadata": {
        "id": "5YDBXLbBaAMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcRVq2iFsA1q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "#\n",
        "#param_grid = {\n",
        "  #  'n_estimators': [50, 100, 200],\n",
        "   # 'max_features': ['auto', 'sqrt', 'log2']\n",
        "#\n",
        "#\n",
        "#grid_search = GridSearchCV(ExtraTreesClassifier(random_state=42), param_grid, cv=5)\n",
        "#grid_search.fit(X_train_selected, y_train_res)\n",
        "#\n",
        "#print(\"Best Parameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "aBl6atpiqEtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_Brgil4sE3W"
      },
      "outputs": [],
      "source": [
        "# Initialize the Extra Trees Classifier\n",
        "etc = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the selected features\n",
        "etc.fit(X_train_selected, y_train_res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTHeDE3IsN3p"
      },
      "outputs": [],
      "source": [
        "# Reorder X_test_selected columns to match X_train_selected\n",
        "X_test_selected = X_test_selected[X_train_selected.columns]\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = etc.predict(X_test_selected)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inHfdMoyx0qp"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After all preprocessing)')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after feature engineering\n"
      ],
      "metadata": {
        "id": "6qJvvjq7aaI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Extra Trees Classifier\n",
        "etc = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the feature-engineered training set\n",
        "etc.fit(X_train_fe, y_train_res)\n",
        "\n",
        "# Reorder X_test_fe columns to match X_train_fe\n",
        "X_test_fe = X_test_fe[X_train_fe.columns]\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = etc.predict(X_test_fe)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Feature Engineering)')"
      ],
      "metadata": {
        "id": "M6kdiZFCanft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after imputation of outlier\n"
      ],
      "metadata": {
        "id": "qcLmc9CBhXlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Extra Trees Classifier\n",
        "etc = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the cleaned training set\n",
        "etc.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# Predict on the cleaned test set\n",
        "y_pred = etc.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Handling Outliers)')"
      ],
      "metadata": {
        "id": "wFOxzAj6hdGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset Before imputation of outlier"
      ],
      "metadata": {
        "id": "F5JbEUr5mc39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Extra Trees Classifier\n",
        "etc = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model using the data before outlier imputation\n",
        "etc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = etc.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Handling Outliers)')"
      ],
      "metadata": {
        "id": "hEzcmBW-mf1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dDZm37VzYRa"
      },
      "source": [
        "##Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after all preprocessing\n"
      ],
      "metadata": {
        "id": "mB6ySqTKw87A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIGpGSh_0Lxb"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heYKk0cc0N8N"
      },
      "outputs": [],
      "source": [
        "# Define the Support Vector Machine model with a linear kernel\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_selected, y_train_res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJYd_-3j0VOz"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test_selected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACKspLpI0VRF"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After All Preprocessing)')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after feature engineering"
      ],
      "metadata": {
        "id": "ryc7XqLGxAJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZHB4lEsay7l"
      },
      "outputs": [],
      "source": [
        "# Define the Support Vector Machine model with a linear kernel\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_fe, y_train_res)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test_fe)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Feature Engineering)')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset after Imputation of Outlier"
      ],
      "metadata": {
        "id": "okFZfYLTyieh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Support Vector Machine model with a linear kernel\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (After Handling Outliers)')"
      ],
      "metadata": {
        "id": "a7JS_qiyx-Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Dataset before Imputation of Outlier"
      ],
      "metadata": {
        "id": "VwcfpRAWyq0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Support Vector Machine model with a linear kernel\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), 'Confusion Matrix Heatmap (Before Handling Outliers)')"
      ],
      "metadata": {
        "id": "cFsIR_ngyeKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}